# Image Classification in Tensorflow


In this blog post, we are going to learn how to construct a machine learning algorithm that classifies images of cats and dogs using `Tensorflow`. Before we get started, we need to load necessary packages. 

For training, validation, and testing, we would use a sample data set provided by the TensorFlow team that contains labeled images of cats and dogs.

## ยง1.Load Packages and Obtain Data


```python
import os
from tensorflow.keras import utils 
import tensorflow as tf
from tensorflow.keras import datasets, layers, models
import matplotlib.pyplot as plt
import numpy as np
import collections

```


```python
# location of data
_URL = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'

# download the data and extract it
path_to_zip = utils.get_file('cats_and_dogs.zip', origin=_URL, extract=True)

# construct paths
PATH = os.path.join(os.path.dirname(path_to_zip), 'cats_and_dogs_filtered')

train_dir = os.path.join(PATH, 'train')
validation_dir = os.path.join(PATH, 'validation')

# parameters for datasets
BATCH_SIZE = 32
IMG_SIZE = (160, 160)

# construct train and validation datasets 
train_dataset = utils.image_dataset_from_directory(train_dir,
                                                   shuffle=True,
                                                   batch_size=BATCH_SIZE,
                                                   image_size=IMG_SIZE)

validation_dataset = utils.image_dataset_from_directory(validation_dir,
                                                        shuffle=True,
                                                        batch_size=BATCH_SIZE,
                                                        image_size=IMG_SIZE)

# construct the test dataset by taking every 5th observation out of the validation dataset
val_batches = tf.data.experimental.cardinality(validation_dataset)
test_dataset = validation_dataset.take(val_batches // 5)
validation_dataset = validation_dataset.skip(val_batches // 5)

```

    Found 2000 files belonging to 2 classes.
    Found 1000 files belonging to 2 classes.


> ## Explore Our Data Set 
To have a sense of what our data set looks like, we would write a `two_row_visualization()` function that displays labeled pictures of dogs and cats.


```python
def two_row_visualization(train_dataset):
  """
  This function shows 
  three random labeled images of cats in the 1st row
  And three random labeled images of dogs in the 2nd row.
  """
  # get the class names
  class_names = train_dataset.class_names

  plt.figure(figsize=(10, 10))
  # retrieve one batch (32 images with labels) from the training data
  for images, labels in train_dataset.take(1):
    # keep track of indices of the images
    idx_cat = []
    idx_dog = []

    # append the label if it is cat and hold 3 labels as max 
    for i in range(len(labels)):
      if len(idx_cat) < 3:
        if class_names[labels[i]] == "cats":
                       idx_cat.append(i)
    
    # append the label if it is dog and hold 3 labels as max 
      if len(idx_dog) < 3:
        if class_names[labels[i]] == "dogs":
                       idx_dog.append(i)

  idx = idx_cat + idx_dog # concatenate the two indices 

  for i in range(6):
    ax = plt.subplot(2, 3, i + 1)
    plt.imshow(images[idx[i]].numpy().astype("uint8"))
    plt.title(class_names[labels[idx[i]]])      
    plt.axis("off")  


```


```python
two_row_visualization(train_dataset)
```


    
![output_7_0.ppng](/images/output_7_0.png)
    


The following chunk of code is the technical code related to rapidly reading data.


```python
AUTOTUNE = tf.data.AUTOTUNE

train_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)
validation_dataset = validation_dataset.prefetch(buffer_size=AUTOTUNE)
test_dataset = test_dataset.prefetch(buffer_size=AUTOTUNE)
```

> ## Check Label Frequencies
The following line of code will create an *iterator* called `labels`.


```python
labels_iterator= train_dataset.unbatch().map(lambda image, label: label).as_numpy_iterator()
```


```python
# compute the number of images in the training data  with label 0 ("cat") and label 1 ("dog")
# using the Counter method which stores dictionary keys and their counts as corresponding dictionary values
collections.Counter(list(labels_iterator))
```




    Counter({0: 1000, 1: 1000})



The *baseline* machine learning model is the model that always guesses the most frequent label. In our case, since we have 50% numbers of *label 0* and 50% numbers of *label 1* (i.e., the two labels have the same frequency), the baseline line model should have an accuracy of 50%.

Our models should obtain accuracy higher than baseline in order to be considered good data science achievements!

## ยง2. First Model 
In this section, we will create a `tf.keras.Sequential` model using some of the layers such as `Conv2D`, `MaxPooling2D`, `Flatten`, `Dense`, and `Dropout` layers.


```python
model1 = models.Sequential([
    # beginning (input)
    # starts with the Conv2D layer with 32 kernels and shape 3*3 
    # passes a non-linear transformation called relu
    # and specifies the input shape (160x160 pixels and three color "channels")                      
    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(160, 160, 3)),

    # hidden layers
    # reduce the number of parameters at each step
    layers.MaxPooling2D((2, 2)),

    # add more layers to make the model "deeper"
    layers.Conv2D(32, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    # Dropout layer deals with overfitting by ensuring that the model doesn't fit too close
    layers.Dropout(0.2),

    # flatten the data from 2d to 1d in order to pass it through the final Dense layers
    layers.Flatten(),

    # end (output)
    # Dense layers form the prediction
    layers.Dense(64, activation='relu'),
    layers.Dense(2) # we have 2 classes
])
```


After we have constructed the model, we can now train our model by using `model.compile(optimizer, loss, metrics)`.


```python
model1.compile(optimizer='adam',
              # apply softmax by specifying from_logits=True 
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy']) # we want to see how accuracy changes

```

Now we can check how it works and plot the history of the accuracy on both the training and validation sets.


```python
history = model1.fit(train_dataset, 
                     epochs=20, 
                     validation_data=validation_dataset)
```

    Epoch 1/20
    63/63 [==============================] - 8s 87ms/step - loss: 4.2468 - accuracy: 0.5450 - val_loss: 0.6920 - val_accuracy: 0.5978
    Epoch 2/20
    63/63 [==============================] - 5s 80ms/step - loss: 0.6379 - accuracy: 0.6425 - val_loss: 0.6581 - val_accuracy: 0.6584
    Epoch 3/20
    63/63 [==============================] - 5s 82ms/step - loss: 0.5392 - accuracy: 0.7205 - val_loss: 0.6342 - val_accuracy: 0.6683
    Epoch 4/20
    63/63 [==============================] - 5s 80ms/step - loss: 0.4723 - accuracy: 0.7625 - val_loss: 0.6884 - val_accuracy: 0.6609
    Epoch 5/20
    63/63 [==============================] - 5s 79ms/step - loss: 0.4354 - accuracy: 0.7865 - val_loss: 0.7449 - val_accuracy: 0.6559
    Epoch 6/20
    63/63 [==============================] - 6s 85ms/step - loss: 0.3726 - accuracy: 0.8295 - val_loss: 0.6773 - val_accuracy: 0.6856
    Epoch 7/20
    63/63 [==============================] - 5s 82ms/step - loss: 0.3369 - accuracy: 0.8580 - val_loss: 1.0001 - val_accuracy: 0.6077
    Epoch 8/20
    63/63 [==============================] - 5s 82ms/step - loss: 0.3640 - accuracy: 0.8315 - val_loss: 0.7569 - val_accuracy: 0.7017
    Epoch 9/20
    63/63 [==============================] - 5s 81ms/step - loss: 0.2484 - accuracy: 0.8950 - val_loss: 0.8600 - val_accuracy: 0.6720
    Epoch 10/20
    63/63 [==============================] - 6s 84ms/step - loss: 0.2276 - accuracy: 0.9090 - val_loss: 0.9963 - val_accuracy: 0.6782
    Epoch 11/20
    63/63 [==============================] - 6s 85ms/step - loss: 0.2030 - accuracy: 0.9155 - val_loss: 1.1278 - val_accuracy: 0.6634
    Epoch 12/20
    63/63 [==============================] - 6s 85ms/step - loss: 0.2082 - accuracy: 0.9205 - val_loss: 0.9492 - val_accuracy: 0.6720
    Epoch 13/20
    63/63 [==============================] - 6s 85ms/step - loss: 0.1770 - accuracy: 0.9315 - val_loss: 0.9600 - val_accuracy: 0.7030
    Epoch 14/20
    63/63 [==============================] - 5s 81ms/step - loss: 0.1406 - accuracy: 0.9460 - val_loss: 1.1818 - val_accuracy: 0.6807
    Epoch 15/20
    63/63 [==============================] - 6s 85ms/step - loss: 0.1056 - accuracy: 0.9605 - val_loss: 1.3397 - val_accuracy: 0.6869
    Epoch 16/20
    63/63 [==============================] - 6s 86ms/step - loss: 0.0893 - accuracy: 0.9705 - val_loss: 1.3492 - val_accuracy: 0.6943
    Epoch 17/20
    63/63 [==============================] - 5s 81ms/step - loss: 0.0880 - accuracy: 0.9645 - val_loss: 1.5210 - val_accuracy: 0.6894
    Epoch 18/20
    63/63 [==============================] - 6s 83ms/step - loss: 0.1005 - accuracy: 0.9620 - val_loss: 1.6264 - val_accuracy: 0.6881
    Epoch 19/20
    63/63 [==============================] - 6s 86ms/step - loss: 0.0799 - accuracy: 0.9725 - val_loss: 1.5792 - val_accuracy: 0.6708
    Epoch 20/20
    63/63 [==============================] - 6s 86ms/step - loss: 0.0974 - accuracy: 0.9650 - val_loss: 1.5523 - val_accuracy: 0.6708



```python
# plot the history accuracy of training and validation data sets
plt.plot(history.history["accuracy"], label = "training")
plt.plot(history.history["val_accuracy"], label = "validation")
plt.gca().set(xlabel = "epoch", ylabel = "accuracy")
plt.legend()
```




    <matplotlib.legend.Legend at 0x7fdefaac1f10>




    
![output_20_1png](/images/output_20_1.png)
    


When constructing the model1, I experimented with the kernel size of `layers.Conv2D` and tried different matrix size for `layers.maxpooling2D`. I've also tried adding more layers to see the performance.

- **The validation accuracy of my model stabilized between 67% and 69% during training.**
- Compared to the 50% baseline accuracy, my model is about 17 to 19 percent better.
- In our case, since the training accuracy is much higher than the validation accuracy, `model1` does display overfitting. 

## ยง3. Model with Data Augmentation
Now weโre going to add some *data augmentation layers* to our model. Data augmentation means including modified copies of the same image in the training set. The purpose of data augmentation is help our model learn invariant features of our input images. 

> Make a plot of the original image (the first image) and a few copies to which `RandomFlip()` has been applied.


```python
RandomFlip = tf.keras.layers.RandomFlip(mode = "horizontal_and_vertical")
```


```python
for image, _ in train_dataset.take(1):
  plt.figure(figsize=(10, 10))
  for i in range(4):
    ax = plt.subplot(1, 4, i + 1)
    # plot the first image as the original image
    if i == 0 :
      plt.imshow(image[0].numpy().astype('uint8'))
      plt.axis('off')
    else:
      augmented_image = RandomFlip(tf.expand_dims(image[0], 0))
      plt.imshow(augmented_image[0] / 255)
      plt.axis('off')
```


    
![output_25_0png](/images/output_25_0.png)
    


> make a plot of both the original image (the first image) and a few copies to which `RandomRotation()` has been applied.


```python
RandomRotation = tf.keras.layers.RandomRotation(0.2)
```


```python
for image, _ in train_dataset.take(1):
  plt.figure(figsize=(10, 10))
  #first_image = image[0]
  for i in range(4):
    ax = plt.subplot(1, 4, i + 1)
    # plot the first image as the original image
    if i == 0 :
      plt.imshow(image[0].numpy().astype('uint8'))
      plt.axis('off')
    else:
      augmented_image = RandomRotation(tf.expand_dims(image[0], 0))
      plt.imshow(augmented_image[0] / 255)
      plt.axis('off')
```


    
![output_28_0.png](/images/output_28_0.png)
    


Now we would apply the `RandomFlip()` and `RandomRotation()` layers and see how this new model performs.


```python
model2 = tf.keras.models.Sequential([
                                     
    # apply the data augmentation layers                                 
    layers.RandomFlip(),
    layers.RandomRotation(0.2),                                 

    # the following layers are the same as in model1                  
    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(160, 160, 3)),
    layers.MaxPooling2D((2, 2)),
    layers.Dropout(0.2),
    layers.Conv2D(32, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Flatten(),

    layers.Dense(64, activation='relu'),
    layers.Dense(2) # we have 2 classes
])
```


```python
# train the model2 on our data set
model2.compile(optimizer='adam',
              # apply softmax by specifying from_logits=True 
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy']) # we want to see how accuracy changes

history = model2.fit(train_dataset, 
                     epochs=20, 
                     validation_data=validation_dataset)

```

    Epoch 1/20
    63/63 [==============================] - 7s 89ms/step - loss: 8.4995 - accuracy: 0.5260 - val_loss: 0.7062 - val_accuracy: 0.5248
    Epoch 2/20
    63/63 [==============================] - 6s 85ms/step - loss: 0.6881 - accuracy: 0.5380 - val_loss: 0.6738 - val_accuracy: 0.5965
    Epoch 3/20
    63/63 [==============================] - 6s 83ms/step - loss: 0.6741 - accuracy: 0.5900 - val_loss: 0.6791 - val_accuracy: 0.5965
    Epoch 4/20
    63/63 [==============================] - 6s 82ms/step - loss: 0.6790 - accuracy: 0.5695 - val_loss: 0.6593 - val_accuracy: 0.6114
    Epoch 5/20
    63/63 [==============================] - 6s 83ms/step - loss: 0.6709 - accuracy: 0.5995 - val_loss: 0.6641 - val_accuracy: 0.6423
    Epoch 6/20
    63/63 [==============================] - 6s 84ms/step - loss: 0.6609 - accuracy: 0.6175 - val_loss: 0.6615 - val_accuracy: 0.6151
    Epoch 7/20
    63/63 [==============================] - 6s 83ms/step - loss: 0.6643 - accuracy: 0.6070 - val_loss: 0.6657 - val_accuracy: 0.6139
    Epoch 8/20
    63/63 [==============================] - 6s 84ms/step - loss: 0.6671 - accuracy: 0.6060 - val_loss: 0.6645 - val_accuracy: 0.6337
    Epoch 9/20
    63/63 [==============================] - 6s 84ms/step - loss: 0.6697 - accuracy: 0.6115 - val_loss: 0.6519 - val_accuracy: 0.6262
    Epoch 10/20
    63/63 [==============================] - 6s 84ms/step - loss: 0.6545 - accuracy: 0.6295 - val_loss: 0.6597 - val_accuracy: 0.6200
    Epoch 11/20
    63/63 [==============================] - 6s 84ms/step - loss: 0.6499 - accuracy: 0.6415 - val_loss: 0.6798 - val_accuracy: 0.5854
    Epoch 12/20
    63/63 [==============================] - 6s 85ms/step - loss: 0.6637 - accuracy: 0.6205 - val_loss: 0.6770 - val_accuracy: 0.5804
    Epoch 13/20
    63/63 [==============================] - 6s 83ms/step - loss: 0.6531 - accuracy: 0.6235 - val_loss: 0.6727 - val_accuracy: 0.5953
    Epoch 14/20
    63/63 [==============================] - 6s 83ms/step - loss: 0.6663 - accuracy: 0.6095 - val_loss: 0.6639 - val_accuracy: 0.6077
    Epoch 15/20
    63/63 [==============================] - 6s 84ms/step - loss: 0.6506 - accuracy: 0.6140 - val_loss: 0.6701 - val_accuracy: 0.6064
    Epoch 16/20
    63/63 [==============================] - 6s 86ms/step - loss: 0.6480 - accuracy: 0.6240 - val_loss: 0.6771 - val_accuracy: 0.5990
    Epoch 17/20
    63/63 [==============================] - 6s 85ms/step - loss: 0.6696 - accuracy: 0.5960 - val_loss: 0.6834 - val_accuracy: 0.5507
    Epoch 18/20
    63/63 [==============================] - 6s 85ms/step - loss: 0.6571 - accuracy: 0.6035 - val_loss: 0.6688 - val_accuracy: 0.6151
    Epoch 19/20
    63/63 [==============================] - 6s 83ms/step - loss: 0.6418 - accuracy: 0.6400 - val_loss: 0.6665 - val_accuracy: 0.6225
    Epoch 20/20
    63/63 [==============================] - 6s 84ms/step - loss: 0.6486 - accuracy: 0.6225 - val_loss: 0.6534 - val_accuracy: 0.6374



```python
# plot the history accuracy of training and validation data sets
plt.plot(history.history["accuracy"], label = "training")
plt.plot(history.history["val_accuracy"], label = "validation")
plt.gca().set(xlabel = "epoch", ylabel = "accuracy")
plt.legend()
```




    <matplotlib.legend.Legend at 0x7fdefaa844d0>




    
![output_32_1.png](/images/output_32_1.png)
    


- **The validation accuracy of model2 stabilized between 61% and 63% during training.**
- Compared to the accuracy of model1 (67%-69%), `model2` is about 6% worse.
- Since the training accuracy is about the same as the validation accuracy, `model2` does **not** display overfitting. 

## ยง4. Data Preprocessing
Sometimes it can be helpful to make simple transformations to the input data so that we can spend more of our training energy handling actual signal in the data and less energy having the weights adjust to the data scale. For example, we can normalize RGB values (originally between 0 and 255) of our original data to 0 and 1, so our model could train faster.

The following code will create a preprocessing layer called `preprocessor` which we can slot into our model pipeline.


```python
i = tf.keras.Input(shape=(160, 160, 3))
x = tf.keras.applications.mobilenet_v2.preprocess_input(i)
preprocessor = tf.keras.Model(inputs = [i], outputs = [x])
```

Now we will incorporate the preprocessing layer into our `model3` and see how it does.


```python
model3 = tf.keras.models.Sequential([

    # apply the preprocessor to get faster training
    preprocessor,

    # apply the data augmentation layers                                 
    layers.RandomFlip(),
    layers.RandomRotation(0.2),                                 

    # the following layers are the same as in model1                  
    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(160, 160, 3)),
    layers.MaxPooling2D((2, 2)),
    layers.Dropout(0.2),
    layers.Conv2D(32, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Flatten(),

    layers.Dense(64, activation='relu'),
    layers.Dense(2) # we have 2 classes
])
```


```python
# train the model3 on our data set
model3.compile(optimizer='adam',
              # apply softmax by specifying from_logits=True 
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy']) # we want to see how accuracy changes

history = model3.fit(train_dataset, 
                     epochs=20, 
                     validation_data=validation_dataset)

```

    Epoch 1/20
    63/63 [==============================] - 7s 86ms/step - loss: 0.7146 - accuracy: 0.5175 - val_loss: 0.6883 - val_accuracy: 0.5953
    Epoch 2/20
    63/63 [==============================] - 6s 85ms/step - loss: 0.6804 - accuracy: 0.5650 - val_loss: 0.6573 - val_accuracy: 0.5891
    Epoch 3/20
    63/63 [==============================] - 5s 82ms/step - loss: 0.6615 - accuracy: 0.5850 - val_loss: 0.6357 - val_accuracy: 0.5903
    Epoch 4/20
    63/63 [==============================] - 5s 82ms/step - loss: 0.6396 - accuracy: 0.6285 - val_loss: 0.6212 - val_accuracy: 0.6597
    Epoch 5/20
    63/63 [==============================] - 6s 83ms/step - loss: 0.6131 - accuracy: 0.6580 - val_loss: 0.6023 - val_accuracy: 0.6634
    Epoch 6/20
    63/63 [==============================] - 5s 82ms/step - loss: 0.6039 - accuracy: 0.6615 - val_loss: 0.5916 - val_accuracy: 0.6745
    Epoch 7/20
    63/63 [==============================] - 5s 83ms/step - loss: 0.5900 - accuracy: 0.6755 - val_loss: 0.5842 - val_accuracy: 0.6782
    Epoch 8/20
    63/63 [==============================] - 5s 82ms/step - loss: 0.5820 - accuracy: 0.6915 - val_loss: 0.5759 - val_accuracy: 0.6980
    Epoch 9/20
    63/63 [==============================] - 5s 83ms/step - loss: 0.5778 - accuracy: 0.6975 - val_loss: 0.5636 - val_accuracy: 0.6993
    Epoch 10/20
    63/63 [==============================] - 5s 83ms/step - loss: 0.5664 - accuracy: 0.6975 - val_loss: 0.5704 - val_accuracy: 0.6968
    Epoch 11/20
    63/63 [==============================] - 5s 82ms/step - loss: 0.5612 - accuracy: 0.7085 - val_loss: 0.5945 - val_accuracy: 0.6795
    Epoch 12/20
    63/63 [==============================] - 5s 82ms/step - loss: 0.5618 - accuracy: 0.6995 - val_loss: 0.5625 - val_accuracy: 0.7042
    Epoch 13/20
    63/63 [==============================] - 6s 83ms/step - loss: 0.5588 - accuracy: 0.7040 - val_loss: 0.5756 - val_accuracy: 0.6844
    Epoch 14/20
    63/63 [==============================] - 5s 82ms/step - loss: 0.5474 - accuracy: 0.7060 - val_loss: 0.5515 - val_accuracy: 0.7079
    Epoch 15/20
    63/63 [==============================] - 5s 82ms/step - loss: 0.5361 - accuracy: 0.7315 - val_loss: 0.5367 - val_accuracy: 0.7290
    Epoch 16/20
    63/63 [==============================] - 6s 83ms/step - loss: 0.5423 - accuracy: 0.7250 - val_loss: 0.5405 - val_accuracy: 0.7153
    Epoch 17/20
    63/63 [==============================] - 6s 84ms/step - loss: 0.5360 - accuracy: 0.7250 - val_loss: 0.5842 - val_accuracy: 0.6745
    Epoch 18/20
    63/63 [==============================] - 6s 83ms/step - loss: 0.5506 - accuracy: 0.7220 - val_loss: 0.5417 - val_accuracy: 0.7228
    Epoch 19/20
    63/63 [==============================] - 6s 85ms/step - loss: 0.5248 - accuracy: 0.7410 - val_loss: 0.5350 - val_accuracy: 0.7302
    Epoch 20/20
    63/63 [==============================] - 6s 88ms/step - loss: 0.5147 - accuracy: 0.7375 - val_loss: 0.5397 - val_accuracy: 0.7376



```python
# plot the history accuracy of training and validation data sets
plt.plot(history.history["accuracy"], label = "training")
plt.plot(history.history["val_accuracy"], label = "validation")
plt.gca().set(xlabel = "epoch", ylabel = "accuracy")
plt.legend()
```

- **The validation accuracy of model3 stabilized around 73% during training.**
- Compared to the accuracy of model1 (67%-69%), `model3` is 4% to 6% better.
- Since the training accuracy is about the same as the validation accuracy, `model3` does **not** display overfitting. 

## ยง5. Transfer Learning
Sometimes we can benefit by adopting a pre-existing model and then build our model on this. This process is called transfer learning. To do this, we need to first access a pre-existing โbase modelโ, incorporate it into a full model for our current task, and then train that model.

The following code downloads `MobileNetV2` and configures it as a layer that can be included in our model.


```python
IMG_SHAPE = IMG_SIZE + (3,)
base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,
                                               include_top=False,
                                               weights='imagenet')
base_model.trainable = False

i = tf.keras.Input(shape=IMG_SHAPE)
x = base_model(i, training = False)
base_model_layer = tf.keras.Model(inputs = [i], outputs = [x])
```

Now we are able to create a model called `model4` that uses `MobileNetV2`.


```python
model4 = tf.keras.models.Sequential([

    # apply the preprocessor to get faster training
    preprocessor,

    # apply the data augmentation layers                                 
    layers.RandomFlip(),
    layers.RandomRotation(0.2),    

    # the base model layer constructed above
    base_model_layer,                           

    # some additional layers                
    layers.GlobalMaxPooling2D(),  
    layers.Dropout(0.2),
    layers.Flatten(),

    layers.Dense(64, activation='relu'),
    layers.Dense(2) # perform the classification
])
```

Now we would like to use the `model4.summary()` method to see the hidden mechanics in the `base_model_layer`.


```python
model4.summary()
```

We can observe that there are **38,492** trainable parameters in this model.


```python
# train the model4 on our data set
model4.compile(optimizer='adam',
              # apply softmax by specifying from_logits=True 
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy']) # we want to see how accuracy changes

history = model4.fit(train_dataset, 
                     epochs=20, 
                     validation_data=validation_dataset)
```

    Epoch 1/20
    63/63 [==============================] - 12s 116ms/step - loss: 0.5489 - accuracy: 0.7940 - val_loss: 0.1241 - val_accuracy: 0.9455
    Epoch 2/20
    63/63 [==============================] - 6s 93ms/step - loss: 0.2809 - accuracy: 0.8790 - val_loss: 0.0945 - val_accuracy: 0.9579
    Epoch 3/20
    63/63 [==============================] - 6s 93ms/step - loss: 0.2404 - accuracy: 0.8940 - val_loss: 0.0876 - val_accuracy: 0.9666
    Epoch 4/20
    63/63 [==============================] - 6s 91ms/step - loss: 0.2260 - accuracy: 0.9090 - val_loss: 0.0743 - val_accuracy: 0.9678
    Epoch 5/20
    63/63 [==============================] - 6s 93ms/step - loss: 0.2126 - accuracy: 0.9140 - val_loss: 0.0778 - val_accuracy: 0.9666
    Epoch 6/20
    63/63 [==============================] - 6s 94ms/step - loss: 0.2093 - accuracy: 0.9110 - val_loss: 0.0789 - val_accuracy: 0.9740
    Epoch 7/20
    63/63 [==============================] - 6s 92ms/step - loss: 0.2051 - accuracy: 0.9125 - val_loss: 0.0781 - val_accuracy: 0.9728
    Epoch 8/20
    63/63 [==============================] - 6s 93ms/step - loss: 0.2210 - accuracy: 0.9075 - val_loss: 0.0791 - val_accuracy: 0.9703
    Epoch 9/20
    63/63 [==============================] - 6s 94ms/step - loss: 0.1825 - accuracy: 0.9195 - val_loss: 0.0831 - val_accuracy: 0.9691
    Epoch 10/20
    63/63 [==============================] - 6s 91ms/step - loss: 0.1900 - accuracy: 0.9215 - val_loss: 0.0718 - val_accuracy: 0.9678
    Epoch 11/20
    63/63 [==============================] - 6s 92ms/step - loss: 0.1856 - accuracy: 0.9260 - val_loss: 0.0684 - val_accuracy: 0.9752
    Epoch 12/20
    63/63 [==============================] - 6s 93ms/step - loss: 0.1892 - accuracy: 0.9245 - val_loss: 0.0707 - val_accuracy: 0.9728
    Epoch 13/20
    63/63 [==============================] - 6s 93ms/step - loss: 0.1851 - accuracy: 0.9270 - val_loss: 0.0721 - val_accuracy: 0.9703
    Epoch 14/20
    63/63 [==============================] - 6s 93ms/step - loss: 0.1615 - accuracy: 0.9345 - val_loss: 0.0625 - val_accuracy: 0.9740
    Epoch 15/20
    63/63 [==============================] - 6s 93ms/step - loss: 0.1821 - accuracy: 0.9260 - val_loss: 0.0699 - val_accuracy: 0.9740
    Epoch 16/20
    63/63 [==============================] - 6s 92ms/step - loss: 0.1794 - accuracy: 0.9275 - val_loss: 0.0672 - val_accuracy: 0.9703
    Epoch 17/20
    63/63 [==============================] - 6s 92ms/step - loss: 0.1653 - accuracy: 0.9335 - val_loss: 0.0644 - val_accuracy: 0.9703
    Epoch 18/20
    63/63 [==============================] - 6s 93ms/step - loss: 0.1882 - accuracy: 0.9255 - val_loss: 0.0869 - val_accuracy: 0.9703
    Epoch 19/20
    63/63 [==============================] - 6s 93ms/step - loss: 0.1826 - accuracy: 0.9255 - val_loss: 0.0665 - val_accuracy: 0.9728
    Epoch 20/20
    63/63 [==============================] - 6s 93ms/step - loss: 0.1697 - accuracy: 0.9270 - val_loss: 0.0647 - val_accuracy: 0.9728



```python
# plot the history accuracy of training and validation data sets
plt.plot(history.history["accuracy"], label = "training")
plt.plot(history.history["val_accuracy"], label = "validation")
plt.gca().set(xlabel = "epoch", ylabel = "accuracy")
plt.legend()
```

- **The validation accuracy of model4 stabilized around 97% during training.**
- `model4` performs better than any of the previous models.
- For the overfitting issue, we can observe that the validation accuracy is even higher than the training accuracy, so `model4` does **not** display overfitting. 

## ยง6. Score on Test Data
`model4` is my most performant model. Let's see how it evaluates on the `test_dataset`.


```python
eval = model4.evaluate(test_dataset)
print("Test accuracy: ", eval[1])
```

    6/6 [==============================] - 1s 61ms/step - loss: 0.0382 - accuracy: 0.9896
    Test accuracy:  0.9895833134651184


We can see that our test accuracy is almost 99%, which is a pretty decent achievement!
